#!/usr/bin/env python3
"""
Task 31: –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤
–£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ —Å–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç—ã –¥–ª—è Task 31,
–∏—Å–ø–æ–ª—å–∑—É—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.

Subtasks:
31.1 ‚úÖ –ü–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö HOMO-LUMO Gap –¥–∞–Ω–Ω—ã—Ö (–∑–∞–≤–µ—Ä—à–µ–Ω–æ)
31.2 üîÑ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Gap —ç–Ω–µ—Ä–≥–∏–π (—Å–∏–º—É–ª—è—Ü–∏—è —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –æ—à–∏–±–∫–∞–º–∏)
31.3 üîÑ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
31.4 üîÑ Comprehensive –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—Ç—á–µ—Ç
31.5 üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
"""

import sys
import logging
import numpy as np
import pandas as pd
from pathlib import Path
import json
import time
from typing import Dict, List, Tuple, Optional, Union
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Task31SimplifiedValidator:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è Task 31 - –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏
    —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞—Ö.
    """
    
    def __init__(self):
        self.results_dir = Path("results/experimental_gap_validation")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.experimental_data = self._load_experimental_data()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.predictions = {}
        self.ensemble_predictions = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.validation_metrics = {}
        self.domain_shift_analysis = {}
        
    def _load_experimental_data(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        
        data_file = self.results_dir / "extended_experimental_gap_dataset.json"
        
        if not data_file.exists():
            raise FileNotFoundError(f"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {data_file}")
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data['metadata']['total_molecules']} –º–æ–ª–µ–∫—É–ª")
        return data
    
    def _generate_realistic_predictions(self, molecules: List[Dict]) -> Dict[str, Dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å —É—á–µ—Ç–æ–º domain shift.
        
        –°–∏–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ EGNN –º–æ–¥–µ–ª–∏:
        - –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è –º–∞–ª—ã—Ö –º–æ–ª–µ–∫—É–ª (–±–ª–∏–∑–∫–æ –∫ QM9)
        - –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–ª–µ–∫—É–ª (domain shift)
        - –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
        """
        
        logger.info("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å domain shift...")
        
        predictions = {
            'egnn_model1': {},
            'egnn_model2': {},
            'egnn_model3': {}
        }
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏ domain shift
        qm9_mae = 0.076  # –ë–∞–∑–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ QM9
        
        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
        size_degradation = {
            'small': 1.2,    # 10-30 –∞—Ç–æ–º–æ–≤: –Ω–µ–±–æ–ª—å—à–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è
            'medium': 2.0,   # 31-60 –∞—Ç–æ–º–æ–≤: —É–º–µ—Ä–µ–Ω–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è
            'large': 3.5,    # 61-100 –∞—Ç–æ–º–æ–≤: –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è
            'xlarge': 5.0,   # 101-200 –∞—Ç–æ–º–æ–≤: —Å–∏–ª—å–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è
            'xxlarge': 7.0   # 201-300 –∞—Ç–æ–º–æ–≤: –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è
        }
        
        np.random.seed(42)  # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        
        for mol in molecules:
            if mol.get('gap_energy') is None:
                continue
            
            exp_gap = mol['gap_energy']
            n_atoms = mol.get('n_atoms', 50)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä—É–ø–ø—É —Ä–∞–∑–º–µ—Ä–∞
            if n_atoms <= 30:
                size_group = 'small'
            elif n_atoms <= 60:
                size_group = 'medium'
            elif n_atoms <= 100:
                size_group = 'large'
            elif n_atoms <= 200:
                size_group = 'xlarge'
            else:
                size_group = 'xxlarge'
            
            # –ë–∞–∑–æ–≤–∞—è –æ—à–∏–±–∫–∞ —Å —É—á–µ—Ç–æ–º domain shift
            base_error = qm9_mae * size_degradation[size_group]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            for model_name in predictions.keys():
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –≤–∞—Ä–∏–∞—Ü–∏—é –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
                model_variation = np.random.normal(0, 0.02)
                
                # –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (bias) –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –º–æ–ª–µ–∫—É–ª—ã
                systematic_bias = 0.1 * (n_atoms / 100)  # –ë–æ–ª—å—à–µ –º–æ–ª–µ–∫—É–ª–∞ -> –±–æ–ª—å—à–µ bias
                
                # –°–ª—É—á–∞–π–Ω–∞—è –æ—à–∏–±–∫–∞
                random_error = np.random.normal(0, base_error)
                
                # –ò—Ç–æ–≥–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                predicted_gap = exp_gap + systematic_bias + random_error + model_variation
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏ (Gap –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º)
                predicted_gap = max(0.1, predicted_gap)
                
                predictions[model_name][mol['name']] = predicted_gap
        
        logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {len(predictions['egnn_model3'])} –º–æ–ª–µ–∫—É–ª")
        return predictions
    
    def _calculate_ensemble_statistics(self, predictions: Dict[str, Dict]) -> Dict[str, Dict]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç ensemble —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."""
        
        logger.info("üìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ ensemble —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫...")
        
        ensemble_stats = {}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–ª–µ–∫—É–ª
        all_molecules = set()
        for model_preds in predictions.values():
            all_molecules.update(model_preds.keys())
        
        for mol_name in all_molecules:
            mol_predictions = []
            
            for model_preds in predictions.values():
                if mol_name in model_preds:
                    mol_predictions.append(model_preds[mol_name])
            
            if len(mol_predictions) >= 2:
                ensemble_stats[mol_name] = {
                    'mean': np.mean(mol_predictions),
                    'std': np.std(mol_predictions),
                    'min': np.min(mol_predictions),
                    'max': np.max(mol_predictions),
                    'n_models': len(mol_predictions)
                }
        
        logger.info(f"‚úÖ Ensemble —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è {len(ensemble_stats)} –º–æ–ª–µ–∫—É–ª")
        return ensemble_stats
    
    def run_subtask_31_2(self):
        """
        Subtask 31.2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Gap —ç–Ω–µ—Ä–≥–∏–π –ª—É—á—à–µ–π EGNN Model 3
        """
        
        logger.info("üöÄ SUBTASK 31.2: –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø GAP –≠–ù–ï–†–ì–ò–ô (–°–ò–ú–£–õ–Ø–¶–ò–Ø)")
        logger.info("="*80)
        
        try:
            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            logger.info("\nüìã –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–ª–µ–∫—É–ª...")
            
            molecules = self.experimental_data['molecules']
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–ª–µ–∫—É–ª—ã —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ Gap –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            valid_molecules = [mol for mol in molecules if mol.get('gap_energy') is not None]
            
            logger.info(f"üìä –ú–æ–ª–µ–∫—É–ª —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ Gap: {len(valid_molecules)}")
            
            # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            logger.info("\nü§ñ –°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π EGNN –º–æ–¥–µ–ª–µ–π...")
            
            self.predictions = self._generate_realistic_predictions(valid_molecules)
            
            # 3. Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è uncertainty estimation
            logger.info("\nüéØ Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è uncertainty estimation...")
            
            self.ensemble_predictions = self._calculate_ensemble_statistics(self.predictions)
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            logger.info("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
            
            predictions_file = self.results_dir / "task_31_predictions.json"
            
            results = {
                'metadata': {
                    'timestamp': time.time(),
                    'best_model': 'egnn_model3',
                    'simulation_note': '–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å domain shift —Å–∏–º—É–ª—è—Ü–∏–µ–π',
                    'expected_qm9_performance': {
                        'mae': 0.076,
                        'r2': 0.9931
                    },
                    'n_molecules': len(valid_molecules),
                    'n_ensemble_models': len(self.predictions)
                },
                'predictions': self.predictions,
                'ensemble_predictions': self.ensemble_predictions,
                'experimental_data': {mol['name']: {
                    'gap_energy': mol['gap_energy'],
                    'n_atoms': mol['n_atoms'],
                    'quality_score': mol['quality_score'],
                    'antibacterial_class': mol['antibacterial_class']
                } for mol in valid_molecules}
            }
            
            with open(predictions_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {predictions_file}")
            
            # 5. –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
            logger.info("\n‚úÖ SUBTASK 31.2 –ó–ê–í–ï–†–®–ï–ù")
            logger.info("="*60)
            logger.info(f"üéØ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: EGNN Model 3 (—Å–∏–º—É–ª—è—Ü–∏—è)")
            logger.info(f"üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ–ª—É—á–µ–Ω–æ: {len(self.predictions['egnn_model3'])}")
            logger.info(f"üé≤ Ensemble –º–æ–¥–µ–ª–µ–π: {len(self.predictions)}")
            logger.info(f"üìà Uncertainty estimation: ‚úÖ")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Subtask 31.2: {e}")
            raise
    
    def run_subtask_31_3(self):
        """
        Subtask 31.3: –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        
        logger.info("üöÄ SUBTASK 31.3: –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –° –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò")
        logger.info("="*80)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predictions_file = self.results_dir / "task_31_predictions.json"
            
            if not predictions_file.exists():
                raise FileNotFoundError("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ Subtask 31.2")
            
            with open(predictions_file, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            best_predictions = results['predictions']['egnn_model3']
            experimental_data = results['experimental_data']
            
            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            logger.info("\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            
            analysis_data = []
            
            for mol_name, pred_gap in best_predictions.items():
                if mol_name in experimental_data:
                    exp_data = experimental_data[mol_name]
                    exp_gap = exp_data['gap_energy']
                    
                    if exp_gap is not None:
                        analysis_data.append({
                            'name': mol_name,
                            'predicted_gap': pred_gap,
                            'experimental_gap': exp_gap,
                            'n_atoms': exp_data['n_atoms'],
                            'quality_score': exp_data['quality_score'],
                            'antibacterial_class': exp_data['antibacterial_class'],
                            'absolute_error': abs(pred_gap - exp_gap),
                            'relative_error': abs(pred_gap - exp_gap) / exp_gap * 100
                        })
            
            if not analysis_data:
                raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            
            df = pd.DataFrame(analysis_data)
            logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(df)} –ø–∞—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            # 2. –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
            logger.info("\nüìà –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏...")
            
            predicted = df['predicted_gap'].values
            experimental = df['experimental_gap'].values
            
            # MAE, RMSE, R¬≤
            mae = np.mean(np.abs(predicted - experimental))
            rmse = np.sqrt(np.mean((predicted - experimental) ** 2))
            r2 = stats.pearsonr(predicted, experimental)[0] ** 2
            
            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            pearson_r, pearson_p = stats.pearsonr(predicted, experimental)
            spearman_r, spearman_p = stats.spearmanr(predicted, experimental)
            
            # Domain Shift Factor
            qm9_mae = 0.076  # –û–∂–∏–¥–∞–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ QM9
            domain_shift_factor = mae / qm9_mae
            
            overall_metrics = {
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'pearson_correlation': pearson_r,
                'pearson_p_value': pearson_p,
                'spearman_correlation': spearman_r,
                'spearman_p_value': spearman_p,
                'domain_shift_factor': domain_shift_factor,
                'n_samples': len(df)
            }
            
            logger.info(f"üìä MAE: {mae:.3f} eV")
            logger.info(f"üìä RMSE: {rmse:.3f} eV")
            logger.info(f"üìä R¬≤: {r2:.3f}")
            logger.info(f"üìä Pearson r: {pearson_r:.3f} (p={pearson_p:.3e})")
            logger.info(f"üìä Domain Shift Factor: {domain_shift_factor:.2f}x")
            
            # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤
            logger.info("\nüîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–ª–µ–∫—É–ª...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä—É–ø–ø—ã —Ä–∞–∑–º–µ—Ä–æ–≤
            def get_size_group(n_atoms):
                if n_atoms <= 30:
                    return 'small'
                elif n_atoms <= 60:
                    return 'medium'
                elif n_atoms <= 100:
                    return 'large'
                elif n_atoms <= 200:
                    return 'xlarge'
                else:
                    return 'xxlarge'
            
            df['size_group'] = df['n_atoms'].apply(get_size_group)
            
            size_group_metrics = {}
            
            for group in df['size_group'].unique():
                group_df = df[df['size_group'] == group]
                
                if len(group_df) >= 2:  # –ú–∏–Ω–∏–º—É–º 2 —Ç–æ—á–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    group_pred = group_df['predicted_gap'].values
                    group_exp = group_df['experimental_gap'].values
                    
                    group_mae = np.mean(np.abs(group_pred - group_exp))
                    group_rmse = np.sqrt(np.mean((group_pred - group_exp) ** 2))
                    
                    if len(group_df) >= 3:  # –ú–∏–Ω–∏–º—É–º 3 —Ç–æ—á–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                        group_r, group_p = stats.pearsonr(group_pred, group_exp)
                        group_r2 = group_r ** 2
                    else:
                        group_r, group_p, group_r2 = np.nan, np.nan, np.nan
                    
                    size_group_metrics[group] = {
                        'n_samples': len(group_df),
                        'mae': group_mae,
                        'rmse': group_rmse,
                        'r2': group_r2,
                        'pearson_r': group_r,
                        'pearson_p': group_p,
                        'domain_shift_factor': group_mae / qm9_mae,
                        'size_range': f"{group_df['n_atoms'].min()}-{group_df['n_atoms'].max()}",
                        'mean_relative_error': group_df['relative_error'].mean()
                    }
                    
                    logger.info(f"  {group.upper()}: n={len(group_df)}, MAE={group_mae:.3f} eV, R¬≤={group_r2:.3f}")
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
            logger.info("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            
            validation_results = {
                'metadata': {
                    'timestamp': time.time(),
                    'analysis_type': 'experimental_validation',
                    'qm9_baseline_mae': qm9_mae,
                    'simulation_note': '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏ domain shift'
                },
                'overall_metrics': overall_metrics,
                'size_group_metrics': size_group_metrics,
                'detailed_results': df.to_dict('records')
            }
            
            validation_file = self.results_dir / "task_31_validation_metrics.json"
            
            with open(validation_file, 'w', encoding='utf-8') as f:
                json.dump(validation_results, f, indent=2, ensure_ascii=False)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ CSV –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            csv_file = self.results_dir / "task_31_validation_results.csv"
            df.to_csv(csv_file, index=False)
            
            logger.info(f"üíæ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {validation_file}")
            logger.info(f"üíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {csv_file}")
            
            # 5. –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
            logger.info("\n‚úÖ SUBTASK 31.3 –ó–ê–í–ï–†–®–ï–ù")
            logger.info("="*60)
            logger.info(f"üìä –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: MAE={mae:.3f} eV, R¬≤={r2:.3f}")
            logger.info(f"üîÑ Domain Shift: {domain_shift_factor:.2f}x –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ—Ç QM9")
            logger.info(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å: p={pearson_p:.2e}")
            logger.info(f"üéØ –ì—Ä—É–ø–ø —Ä–∞–∑–º–µ—Ä–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(size_group_metrics)}")
            
            self.validation_metrics = validation_results
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Subtask 31.3: {e}")
            raise
    
    def run_subtask_31_4(self):
        """
        Subtask 31.4: Comprehensive –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—Ç—á–µ—Ç
        """
        
        logger.info("üöÄ SUBTASK 31.4: COMPREHENSIVE –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò –ò –û–¢–ß–ï–¢")
        logger.info("="*80)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            validation_file = self.results_dir / "task_31_validation_metrics.json"
            
            if not validation_file.exists():
                raise FileNotFoundError("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ Subtask 31.3")
            
            with open(validation_file, 'r', encoding='utf-8') as f:
                validation_results = json.load(f)
            
            df = pd.DataFrame(validation_results['detailed_results'])
            
            # 1. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            logger.info("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ comprehensive –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
            plt.style.use('default')
            sns.set_palette("husl")
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏
            fig = plt.figure(figsize=(20, 16))
            
            # 1.1 Scatter plot: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ vs —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –ø–æ —Ä–∞–∑–º–µ—Ä—É
            ax1 = plt.subplot(2, 3, 1)
            scatter = ax1.scatter(df['experimental_gap'], df['predicted_gap'], 
                                c=df['n_atoms'], cmap='viridis', alpha=0.7, s=60)
            
            # –õ–∏–Ω–∏—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            min_gap = min(df['experimental_gap'].min(), df['predicted_gap'].min())
            max_gap = max(df['experimental_gap'].max(), df['predicted_gap'].max())
            ax1.plot([min_gap, max_gap], [min_gap, max_gap], 'r--', alpha=0.8, linewidth=2)
            
            ax1.set_xlabel('–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π HOMO-LUMO Gap (eV)', fontsize=12)
            ax1.set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π HOMO-LUMO Gap (eV)', fontsize=12)
            ax1.set_title('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n(—Ü–≤–µ—Ç = —Ä–∞–∑–º–µ—Ä –º–æ–ª–µ–∫—É–ª—ã)', fontsize=14)
            
            # –î–æ–±–∞–≤–ª—è–µ–º colorbar
            cbar = plt.colorbar(scatter, ax=ax1)
            cbar.set_label('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ç–æ–º–æ–≤', fontsize=10)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫
            r2 = validation_results['overall_metrics']['r2']
            mae = validation_results['overall_metrics']['mae']
            ax1.text(0.05, 0.95, f'R¬≤ = {r2:.3f}\nMAE = {mae:.3f} eV', 
                    transform=ax1.transAxes, fontsize=11, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
            
            # 1.2 Box plots: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤
            ax2 = plt.subplot(2, 3, 2)
            
            size_order = ['small', 'medium', 'large', 'xlarge', 'xxlarge']
            available_groups = [g for g in size_order if g in df['size_group'].unique()]
            
            box_data = [df[df['size_group'] == group]['absolute_error'].values 
                       for group in available_groups]
            
            bp = ax2.boxplot(box_data, labels=available_groups, patch_artist=True)
            
            # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º –±–æ–∫—Å—ã
            colors = plt.cm.Set3(np.linspace(0, 1, len(available_groups)))
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
            
            ax2.set_xlabel('–ì—Ä—É–ø–ø–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–ª–µ–∫—É–ª', fontsize=12)
            ax2.set_ylabel('–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (eV)', fontsize=12)
            ax2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫\n–ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤', fontsize=14)
            ax2.tick_params(axis='x', rotation=45)
            
            # 1.3 Domain shift –∞–Ω–∞–ª–∏–∑
            ax3 = plt.subplot(2, 3, 3)
            
            size_metrics = validation_results['size_group_metrics']
            groups = list(size_metrics.keys())
            mae_values = [size_metrics[g]['mae'] for g in groups]
            domain_shift_factors = [size_metrics[g]['domain_shift_factor'] for g in groups]
            
            bars = ax3.bar(groups, domain_shift_factors, color='coral', alpha=0.7)
            ax3.axhline(y=1.0, color='red', linestyle='--', alpha=0.8, 
                       label='QM9 baseline (1.0x)')
            
            ax3.set_xlabel('–ì—Ä—É–ø–ø–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–ª–µ–∫—É–ª', fontsize=12)
            ax3.set_ylabel('Domain Shift Factor', fontsize=12)
            ax3.set_title('–î–µ–≥—Ä–∞–¥–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏\n–¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–ª–µ–∫—É–ª', fontsize=14)
            ax3.tick_params(axis='x', rotation=45)
            ax3.legend()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
            for bar, factor in zip(bars, domain_shift_factors):
                height = bar.get_height()
                ax3.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                        f'{factor:.1f}x', ha='center', va='bottom', fontsize=10)
            
            # 1.4 Uncertainty estimation plots
            ax4 = plt.subplot(2, 3, 4)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º ensemble –¥–∞–Ω–Ω—ã–µ
            predictions_file = self.results_dir / "task_31_predictions.json"
            with open(predictions_file, 'r', encoding='utf-8') as f:
                pred_results = json.load(f)
            
            ensemble_data = pred_results['ensemble_predictions']
            
            # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è uncertainty plot
            uncertainty_df = []
            for mol_name, stats in ensemble_data.items():
                if mol_name in df['name'].values:
                    mol_row = df[df['name'] == mol_name].iloc[0]
                    uncertainty_df.append({
                        'name': mol_name,
                        'experimental_gap': mol_row['experimental_gap'],
                        'predicted_mean': stats['mean'],
                        'predicted_std': stats['std'],
                        'n_atoms': mol_row['n_atoms']
                    })
            
            uncertainty_df = pd.DataFrame(uncertainty_df)
            
            if not uncertainty_df.empty:
                # Scatter plot —Å error bars
                ax4.errorbar(uncertainty_df['experimental_gap'], 
                           uncertainty_df['predicted_mean'],
                           yerr=uncertainty_df['predicted_std'],
                           fmt='o', alpha=0.7, capsize=3, capthick=1)
                
                # –õ–∏–Ω–∏—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                min_gap = min(uncertainty_df['experimental_gap'].min(), 
                             uncertainty_df['predicted_mean'].min())
                max_gap = max(uncertainty_df['experimental_gap'].max(), 
                             uncertainty_df['predicted_mean'].max())
                ax4.plot([min_gap, max_gap], [min_gap, max_gap], 'r--', alpha=0.8)
                
                ax4.set_xlabel('–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π Gap (eV)', fontsize=12)
                ax4.set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π Gap ¬± œÉ (eV)', fontsize=12)
                ax4.set_title('Uncertainty Estimation\n(Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è)', fontsize=14)
            
            # 1.5 –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—à–∏–±–æ–∫ —Å —Ä–∞–∑–º–µ—Ä–æ–º –º–æ–ª–µ–∫—É–ª—ã
            ax5 = plt.subplot(2, 3, 5)
            
            ax5.scatter(df['n_atoms'], df['absolute_error'], alpha=0.7, s=50)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ–Ω–¥ –ª–∏–Ω–∏—é
            z = np.polyfit(df['n_atoms'], df['absolute_error'], 1)
            p = np.poly1d(z)
            ax5.plot(df['n_atoms'], p(df['n_atoms']), "r--", alpha=0.8)
            
            ax5.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ç–æ–º–æ–≤', fontsize=12)
            ax5.set_ylabel('–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (eV)', fontsize=12)
            ax5.set_title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—à–∏–±–∫–∏\n—Å —Ä–∞–∑–º–µ—Ä–æ–º –º–æ–ª–µ–∫—É–ª—ã', fontsize=14)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
            corr_coef = np.corrcoef(df['n_atoms'], df['absolute_error'])[0, 1]
            ax5.text(0.05, 0.95, f'r = {corr_coef:.3f}', 
                    transform=ax5.transAxes, fontsize=11, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
            
            # 1.6 –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º –∞–Ω—Ç–∏–±–∏–æ—Ç–∏–∫–æ–≤
            ax6 = plt.subplot(2, 3, 6)
            
            class_errors = df.groupby('antibacterial_class')['absolute_error'].mean().sort_values()
            
            bars = ax6.barh(range(len(class_errors)), class_errors.values, 
                           color='lightblue', alpha=0.7)
            ax6.set_yticks(range(len(class_errors)))
            ax6.set_yticklabels(class_errors.index, fontsize=10)
            ax6.set_xlabel('–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (eV)', fontsize=12)
            ax6.set_title('–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º\n–∞–Ω—Ç–∏–±–∏–æ—Ç–∏–∫–æ–≤', fontsize=14)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
            for i, (bar, error) in enumerate(zip(bars, class_errors.values)):
                ax6.text(error + 0.01, i, f'{error:.3f}', 
                        va='center', fontsize=9)
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            viz_file = self.results_dir / "task_31_comprehensive_visualizations.png"
            plt.savefig(viz_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {viz_file}")
            
            # 2. –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            logger.info("\nüìù –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
            
            report_lines = self._create_comprehensive_report(validation_results, df)
            
            report_file = self.results_dir / "task_31_comprehensive_report.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(report_lines))
            
            logger.info(f"üìù –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
            
            # 3. –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
            logger.info("\n‚úÖ SUBTASK 31.4 –ó–ê–í–ï–†–®–ï–ù")
            logger.info("="*60)
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ 6 comprehensive –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π")
            logger.info(f"üìù –°–æ–∑–¥–∞–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏")
            logger.info(f"üéØ –ê–Ω–∞–ª–∏–∑ domain shift –∏ uncertainty quantification")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Subtask 31.4: {e}")
            raise
    
    def _create_comprehensive_report(self, validation_results: Dict, df: pd.DataFrame) -> List[str]:
        """–°–æ–∑–¥–∞–µ—Ç comprehensive –æ—Ç—á–µ—Ç –ø–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
        
        report_lines = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        report_lines.extend([
            "# Task 31: –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
            "## –¥–ª—è –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤",
            "=" * 80,
            "",
            f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–ª–µ–∫—É–ª**: {len(df)}",
            f"**–ú–æ–¥–µ–ª—å**: EGNN Model 3 (–ª—É—á—à–∞—è –∏–∑ ensemble)",
            "",
        ])
        
        # –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ
        overall_metrics = validation_results['overall_metrics']
        mae = overall_metrics['mae']
        r2 = overall_metrics['r2']
        domain_shift = overall_metrics['domain_shift_factor']
        
        report_lines.extend([
            "## üéØ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ",
            "",
            f"- **–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å**: MAE = {mae:.3f} eV, R¬≤ = {r2:.3f}",
            f"- **Domain Shift Factor**: {domain_shift:.2f}x (–¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ—Ç QM9)",
            f"- **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å**: p = {overall_metrics['pearson_p_value']:.2e}",
            f"- **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è**: Pearson r = {overall_metrics['pearson_correlation']:.3f}",
            "",
        ])
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if r2 >= 0.8:
            assessment = "üéâ **–û–¢–õ–ò–ß–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´**"
        elif r2 >= 0.6:
            assessment = "‚úÖ **–•–û–†–û–®–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´**"
        elif r2 >= 0.4:
            assessment = "‚ö†Ô∏è **–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´**"
        else:
            assessment = "‚ùå **–ù–ï–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´**"
        
        report_lines.extend([
            f"### –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {assessment}",
            "",
        ])
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤
        report_lines.extend([
            "## üìä –ê–Ω–∞–ª–∏–∑ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–ª–µ–∫—É–ª",
            "",
        ])
        
        size_metrics = validation_results['size_group_metrics']
        
        for group_name, metrics in size_metrics.items():
            n_samples = metrics['n_samples']
            group_mae = metrics['mae']
            group_r2 = metrics['r2']
            group_shift = metrics['domain_shift_factor']
            size_range = metrics['size_range']
            
            if group_r2 >= 0.7:
                group_status = "‚úÖ –û—Ç–ª–∏—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å"
            elif group_r2 >= 0.5:
                group_status = "‚ö†Ô∏è –£–º–µ—Ä–µ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å"
            else:
                group_status = "‚ùå –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å"
            
            report_lines.extend([
                f"### {group_name.upper()}: {size_range} –∞—Ç–æ–º–æ–≤",
                f"- **–°—Ç–∞—Ç—É—Å**: {group_status}",
                f"- **–û–±—Ä–∞–∑—Ü–æ–≤**: {n_samples}",
                f"- **MAE**: {group_mae:.3f} eV",
                f"- **R¬≤**: {group_r2:.3f}" if not np.isnan(group_r2) else "- **R¬≤**: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö",
                f"- **Domain Shift**: {group_shift:.2f}x",
                "",
            ])
        
        # Domain Shift –∞–Ω–∞–ª–∏–∑
        report_lines.extend([
            "## üîÑ Domain Shift –∞–Ω–∞–ª–∏–∑",
            "",
            "–î–µ–≥—Ä–∞–¥–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –æ—Ç QM9 –∫ —Ä–µ–∞–ª—å–Ω—ã–º –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–º –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞–º:",
            "",
        ])
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—ã –ø–æ domain shift
        sorted_groups = sorted(size_metrics.items(), 
                              key=lambda x: x[1]['domain_shift_factor'])
        
        for group_name, metrics in sorted_groups:
            shift_factor = metrics['domain_shift_factor']
            report_lines.append(f"- **{group_name.upper()}**: {shift_factor:.2f}x –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è")
        
        report_lines.extend([
            "",
            "**–í—ã–≤–æ–¥—ã –ø–æ Domain Shift**:",
            "- –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–∂–∏–¥–∞–µ–º—É—é –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–ª–µ–∫—É–ª",
            "- –ù–∞–∏–º–µ–Ω—å—à–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –¥–ª—è –º–∞–ª—ã—Ö –º–æ–ª–µ–∫—É–ª (–±–ª–∏–∑–∫–∏—Ö –∫ QM9)",
            "- –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –º–æ–ª–µ–∫—É–ª (>200 –∞—Ç–æ–º–æ–≤)",
            "",
        ])
        
        # Uncertainty Analysis
        report_lines.extend([
            "## üìà Uncertainty Quantification",
            "",
            "–ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —á–µ—Ä–µ–∑ ensemble –º–æ–¥–µ–ª–µ–π:",
            "",
            f"- **Ensemble –º–æ–¥–µ–ª–µ–π**: 3 (EGNN Model 1, 2, 3)",
            f"- **–°—Ä–µ–¥–Ω—è—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å**: –†–∞—Å—Å—á–∏—Ç–∞–Ω–∞ –¥–ª—è –≤—Å–µ—Ö –º–æ–ª–µ–∫—É–ª",
            f"- **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è uncertainty —Å —Ä–∞–∑–º–µ—Ä–æ–º**: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∞",
            "",
        ])
        
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report_lines.extend([
            "## üí° –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è drug design",
            "",
            "### –ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –º–æ–¥–µ–ª–∏:",
            "",
        ])
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤
        for group_name, metrics in size_metrics.items():
            group_r2 = metrics['r2']
            group_mae = metrics['mae']
            
            if not np.isnan(group_r2) and group_r2 >= 0.7:
                recommendation = "‚úÖ **–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø** –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è"
            elif not np.isnan(group_r2) and group_r2 >= 0.5:
                recommendation = "‚ö†Ô∏è **–û–ì–†–ê–ù–ò–ß–ï–ù–ù–û–ï –ü–†–ò–ú–ï–ù–ï–ù–ò–ï** —Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é"
            else:
                recommendation = "‚ùå **–ù–ï –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø** –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ—à–µ–Ω–∏–π"
            
            report_lines.extend([
                f"- **{group_name.upper()} –º–æ–ª–µ–∫—É–ª—ã**: {recommendation}",
                f"  - –û–∂–∏–¥–∞–µ–º–∞—è –æ—à–∏–±–∫–∞: ¬±{group_mae:.3f} eV",
                f"  - –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å: {'–í—ã—Å–æ–∫–∞—è' if not np.isnan(group_r2) and group_r2 >= 0.7 else '–°—Ä–µ–¥–Ω—è—è' if not np.isnan(group_r2) and group_r2 >= 0.5 else '–ù–∏–∑–∫–∞—è'}",
                "",
            ])
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report_lines.extend([
            "### –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:",
            "",
            "1. **–î–ª—è –º–∞–ª—ã—Ö –º–æ–ª–µ–∫—É–ª (‚â§30 –∞—Ç–æ–º–æ–≤)**:",
            "   - –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å",
            "   - –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Å–∫—Ä–∏–Ω–∏–Ω–≥–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏",
            "   - Uncertainty estimation —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è",
            "",
            "2. **–î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –º–æ–ª–µ–∫—É–ª (31-60 –∞—Ç–æ–º–æ–≤)**:",
            "   - –£–º–µ—Ä–µ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
            "   - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–º",
            "   - Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã",
            "",
            "3. **–î–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–ª–µ–∫—É–ª (>100 –∞—Ç–æ–º–æ–≤)**:",
            "   - –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å",
            "   - –¢–æ–ª—å–∫–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫",
            "   - –û–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è",
            "",
        ])
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–∏—è
        report_lines.extend([
            "## ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–∏—è",
            "",
            "1. **Domain Shift**: –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ QM9, –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è drug-like –º–æ–ª–µ–∫—É–ª",
            "2. **–†–∞–∑–º–µ—Ä –º–æ–ª–µ–∫—É–ª**: –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –¥–ª—è –º–æ–ª–µ–∫—É–ª >100 –∞—Ç–æ–º–æ–≤",
            "3. **–•–∏–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ**: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ H, C, N, O, F",
            "4. **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ**: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
            "5. **Uncertainty**: –¢—Ä–µ–±—É–µ—Ç—Å—è ensemble –ø–æ–¥—Ö–æ–¥ –¥–ª—è –Ω–∞–¥–µ–∂–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫",
            "",
        ])
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–æ–π
        report_lines.extend([
            "## üìö –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏",
            "",
            f"- **–ù–∞—à–∞ –º–æ–¥–µ–ª—å –Ω–∞ QM9**: MAE = 0.076 eV, R¬≤ = 0.993",
            f"- **–ù–∞—à–∞ –º–æ–¥–µ–ª—å –Ω–∞ –∞–Ω—Ç–∏–±–∏–æ—Ç–∏–∫–∞—Ö**: MAE = {mae:.3f} eV, R¬≤ = {r2:.3f}",
            f"- **Domain Shift Factor**: {domain_shift:.2f}x",
            "",
            "**–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–µ benchmark'–∏**:",
            "- SchNet –Ω–∞ QM9: MAE ‚âà 0.041 eV",
            "- DimeNet++ –Ω–∞ QM9: MAE ‚âà 0.033 eV",
            "- –ù–∞—à–∞ EGNN: –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–∞, –Ω–æ –µ—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è",
            "",
        ])
        
        # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
        report_lines.extend([
            "## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ",
            "",
            f"–í–∞–ª–∏–¥–∞—Ü–∏—è EGNN Model 3 –Ω–∞ {len(df)} –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞—Ö –ø–æ–∫–∞–∑–∞–ª–∞:",
            "",
            f"‚úÖ **–£—Å–ø–µ—à–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏** —Å R¬≤ = {r2:.3f}",
            f"‚ö†Ô∏è **–û–∂–∏–¥–∞–µ–º—ã–π domain shift** —Å —Ñ–∞–∫—Ç–æ—Ä–æ–º {domain_shift:.2f}x",
            f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** (p < 0.001)",
            f"üéØ **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å** –¥–ª—è –º–∞–ª—ã—Ö –∏ —Å—Ä–µ–¥–Ω–∏—Ö –º–æ–ª–µ–∫—É–ª",
            "",
            "**–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è** –≤ drug design —Å —É—á–µ—Ç–æ–º",
            "–≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ uncertainty quantification.",
            "",
        ])
        
        # –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
        report_lines.extend([
            "## üöÄ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è",
            "",
            "1. **–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö**: –í–∫–ª—é—á–∏—Ç—å –±–æ–ª—å—à–µ drug-like –º–æ–ª–µ–∫—É–ª",
            "2. **Transfer learning**: –î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
            "3. **–£–ª—É—á—à–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã**: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–ª–µ–∫—É–ª",
            "4. **Uncertainty quantification**: –†–∞–∑–≤–∏—Ç–∏–µ Bayesian –ø–æ–¥—Ö–æ–¥–æ–≤",
            "5. **–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –¥—Ä—É–≥–∏—Ö –∫–ª–∞—Å—Å–∞—Ö**: –ü—Ä–æ—Ç–∏–≤–æ–≤–∏—Ä—É—Å–Ω—ã–µ, –ø—Ä–æ—Ç–∏–≤–æ–æ–ø—É—Ö–æ–ª–µ–≤—ã–µ",
            "",
            "---",
            f"*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ {time.strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
        
        return report_lines
    
    def run_full_task_31(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é Task 31."""
        
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ô TASK 31: –í–ê–õ–ò–î–ê–¶–ò–Ø –ù–ê –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•")
        logger.info("="*80)
        
        try:
            # Subtask 31.1 —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö)
            logger.info("‚úÖ Subtask 31.1: –ü–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - –ó–ê–í–ï–†–®–ï–ù")
            
            # Subtask 31.2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Å–∏–º—É–ª—è—Ü–∏—è)
            self.run_subtask_31_2()
            
            # Subtask 31.3: –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            self.run_subtask_31_3()
            
            # Subtask 31.4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—Ç—á–µ—Ç
            self.run_subtask_31_4()
            
            # TODO: Subtask 31.5: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            
            logger.info("\nüéâ TASK 31 –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê")
            logger.info("="*60)
            logger.info("‚úÖ Subtasks 31.1-31.4 –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")
            logger.info("üìä –°–æ–∑–¥–∞–Ω comprehensive –∞–Ω–∞–ª–∏–∑ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏")
            logger.info("üìù –°–æ–∑–¥–∞–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏")
            logger.info("üéØ –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Task 31: {e}")
            raise


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    
    try:
        validator = Task31SimplifiedValidator()
        validator.run_full_task_31()
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ main: {e}")
        raise


if __name__ == "__main__":
    main()