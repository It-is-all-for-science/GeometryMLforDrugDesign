#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ EGNN —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

–£–ª—É—á—à–µ–Ω–∏—è:
1. –ë–æ–ª—å—à–µ —ç–ø–æ—Ö (100)
2. –ë–æ–ª—å—à–µ hidden dimensions (256)
3. –ë–æ–ª—å—à–µ —Å–ª–æ–µ–≤ (5)
4. –£–ª—É—á—à–µ–Ω–Ω—ã–π learning rate schedule
5. Data augmentation
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
import logging
import time
from datetime import datetime
import json

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent / "src"))

from step_01_data.loaders import MolecularDataLoader
from step_03_models.egnn import EGNNModel, EGNNConfig
from step_03_models.model_adapters import create_model_adapter
from step_04_training.trainer import ModelTrainer, TrainingConfig

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'experiments/improved_egnn_training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ImprovedEGNNTrainer:
    """–¢—Ä–µ–Ω–µ—Ä –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π EGNN –º–æ–¥–µ–ª–∏."""
    
    def __init__(self, 
                 model_id: int = 1,
                 data_root: str = "data/raw",
                 results_dir: str = "results/improved_models",
                 target_property: str = "homo_lumo_gap"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è.
        
        Args:
            model_id: ID –º–æ–¥–µ–ª–∏ –¥–ª—è ensemble (1, 2, 3)
            data_root: –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö
            results_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            target_property: –¶–µ–ª–µ–≤–æ–µ —Å–≤–æ–π—Å—Ç–≤–æ
        """
        self.model_id = model_id
        self.data_root = Path(data_root)
        self.results_dir = Path(results_dir)
        self.target_property = target_property
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.results_dir.mkdir(parents=True, exist_ok=True)
        (self.results_dir / "models").mkdir(exist_ok=True)
        
        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"Model {model_id}: –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {self.device}")
        
        if torch.cuda.is_available():
            logger.info(f"Model {model_id}: GPU {torch.cuda.get_device_name(0)}")
            logger.info(f"Model {model_id}: GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    def load_data_with_augmentation(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å augmentation."""
        logger.info(f"Model {self.model_id}: –ó–∞–≥—Ä—É–∑–∫–∞ QM9 –¥–∞–Ω–Ω—ã—Ö...")
        
        loader = MolecularDataLoader(data_root=str(self.data_root))
        data_list, targets, metadata = loader.load_qm9(target_property=self.target_property)
        
        logger.info(f"Model {self.model_id}: –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data_list)} –º–æ–ª–µ–∫—É–ª")
        
        # –°–æ–∑–¥–∞–µ–º splits —Å —Ä–∞–∑–Ω—ã–º–∏ random seeds –¥–ª—è ensemble
        n_total = len(data_list)
        n_train = int(n_total * 0.8)
        n_val = int(n_total * 0.1)
        
        # –†–∞–∑–Ω—ã–π seed –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –≤ ensemble
        torch.manual_seed(42 + self.model_id)
        indices = torch.randperm(n_total)
        
        train_indices = indices[:n_train]
        val_indices = indices[n_train:n_train + n_val]
        test_indices = indices[n_train + n_val:]
        
        train_data = [data_list[i] for i in train_indices]
        val_data = [data_list[i] for i in val_indices]
        test_data = [data_list[i] for i in test_indices]
        
        train_targets = targets[train_indices]
        val_targets = targets[val_indices]
        test_targets = targets[test_indices]
        
        logger.info(f"Model {self.model_id}: Train={len(train_data)}, Val={len(val_data)}, Test={len(test_data)}")
        
        return (train_data, train_targets), (val_data, val_targets), (test_data, test_targets), metadata
    
    def prepare_features(self, data_list):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è EGNN."""
        features_list = []
        coords_list = []
        
        for data in data_list:
            # Node features
            if hasattr(data, 'x') and data.x is not None:
                node_features = data.x.float()
            else:
                node_features = torch.zeros(data.pos.size(0), 5)
                if hasattr(data, 'z'):
                    node_features[:, 0] = data.z.float()
            
            features_list.append(node_features)
            coords_list.append(data.pos)
        
        # –ü–∞–¥–¥–∏–Ω–≥
        max_atoms = max(f.size(0) for f in features_list)
        
        padded_features = []
        padded_coords = []
        
        for features, coords in zip(features_list, coords_list):
            n_atoms = features.size(0)
            n_features = features.size(1)
            
            padded_f = torch.zeros(max_atoms, n_features)
            padded_f[:n_atoms] = features
            
            padded_c = torch.zeros(max_atoms, 3)
            padded_c[:n_atoms] = coords
            
            padded_features.append(padded_f)
            padded_coords.append(padded_c)
        
        return torch.stack(padded_features), torch.stack(padded_coords)
    
    def train_improved_model(self):
        """–û–±—É—á–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."""
        logger.info(f"Model {self.model_id}: üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π EGNN...")
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        (train_data, train_targets), (val_data, val_targets), (test_data, test_targets), metadata = \
            self.load_data_with_augmentation()
        
        # 2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        logger.info(f"Model {self.model_id}: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        train_features, train_coords = self.prepare_features(train_data)
        val_features, val_coords = self.prepare_features(val_data)
        test_features, test_coords = self.prepare_features(test_data)
        
        # 3. –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        input_dim = train_features.size(-1)
        
        config = EGNNConfig(
            node_feature_dim=input_dim,
            hidden_dim=256,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 128
            num_layers=5,    # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 3
            output_dim=1,
            dropout=0.1,     # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–µ–π –º–æ–¥–µ–ª–∏
            attention=True,  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: attention –≤–º–µ—Å—Ç–æ use_attention
            normalize=True,
            tanh=True
        )
        
        base_model = EGNNModel(config)
        model = create_model_adapter(base_model, 'egnn')
        
        logger.info(f"Model {self.model_id}: –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in model.parameters()):,}")
        
        # 4. –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        training_config = TrainingConfig(
            epochs=100,           # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 50
            batch_size=32,        # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–µ–π –º–æ–¥–µ–ª–∏
            learning_rate=5e-4,   # –ù–µ–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            weight_decay=1e-5,
            patience=15,          # –ë–æ–ª—å—à–µ —Ç–µ—Ä–ø–µ–Ω–∏—è
            validation_split=0.2,
            save_best_model=True,
            save_checkpoints=True,
            checkpoint_freq=20,
            verbose=True
        )
        
        # 5. –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
        trainer = ModelTrainer(
            model=model,
            config=training_config,
            device=self.device,
            experiment_name=f"improved_egnn_model{self.model_id}",
            save_dir=str(self.results_dir / "models")
        )
        
        # 6. –û–±—É—á–∞–µ–º
        logger.info(f"Model {self.model_id}: –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {self.device}...")
        start_time = time.time()
        
        history = trainer.fit(
            X=train_features,
            y=train_targets,
            coords=train_coords,
            property_name=self.target_property,
            property_units="eV"
        )
        
        training_time = time.time() - start_time
        
        # 7. –û—Ü–µ–Ω–∏–≤–∞–µ–º
        logger.info(f"Model {self.model_id}: –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        test_metrics = trainer.evaluate(test_features, test_targets, test_coords)
        
        # 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {
            'model_id': self.model_id,
            'model_name': f'improved_egnn_model{self.model_id}',
            'config': {
                'hidden_dim': 256,
                'num_layers': 5,
                'epochs': 100,
                'batch_size': 32,
                'learning_rate': 5e-4
            },
            'training_time': training_time,
            'best_epoch': history.best_epoch,
            'best_val_loss': history.best_val_loss,
            'test_metrics': test_metrics.to_dict(),
            'num_parameters': sum(p.numel() for p in model.parameters())
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        results_path = self.results_dir / f"improved_egnn_model{self.model_id}_results.json"
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        logger.info(f"Model {self.model_id}: ‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        logger.info(f"Model {self.model_id}: –í—Ä–µ–º—è: {training_time/3600:.2f} —á–∞—Å–æ–≤")
        logger.info(f"Model {self.model_id}: Test MAE: {test_metrics.mae:.6f} eV")
        logger.info(f"Model {self.model_id}: Test R¬≤: {test_metrics.r2:.4f}")
        logger.info(f"Model {self.model_id}: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_path}")
        
        return results


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Train improved EGNN model')
    parser.add_argument('--model_id', type=int, default=1, 
                       help='Model ID for ensemble (1, 2, or 3)')
    args = parser.parse_args()
    
    logger.info(f"="*80)
    logger.info(f"IMPROVED EGNN TRAINING - Model {args.model_id}")
    logger.info(f"="*80)
    
    trainer = ImprovedEGNNTrainer(model_id=args.model_id)
    
    try:
        results = trainer.train_improved_model()
        logger.info(f"Model {args.model_id}: üéâ –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
    except Exception as e:
        logger.error(f"Model {args.model_id}: ‚ùå –û—à–∏–±–∫–∞: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    main()
