#!/usr/bin/env python3
"""
Task 31: –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –ª—É—á—à–µ–π EGNN Model 3 –Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
–∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤ —Å –∞–Ω–∞–ª–∏–∑–æ–º domain shift –∏ uncertainty quantification.

Subtasks:
31.1 ‚úÖ –ü–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö HOMO-LUMO Gap –¥–∞–Ω–Ω—ã—Ö (–∑–∞–≤–µ—Ä—à–µ–Ω–æ)
31.2 üîÑ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Gap —ç–Ω–µ—Ä–≥–∏–π –ª—É—á—à–µ–π EGNN Model 3
31.3 üîÑ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
31.4 üîÑ Comprehensive –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—Ç—á–µ—Ç
31.5 üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
"""

import sys
import logging
import numpy as np
import pandas as pd
from pathlib import Path
import json
import time
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Optional, Union
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –Ω–∞—à–∏–º –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent.parent / "src"))

try:
    from rdkit import Chem
    from rdkit.Chem import Descriptors, rdMolDescriptors, AllChem
    RDKIT_AVAILABLE = True
except ImportError:
    RDKIT_AVAILABLE = False
    logging.warning("RDKit –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

from step_03_models.egnn import EGNNModel, EGNNConfig
from step_01_data.loaders import MolecularDataLoader

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Task31ExperimentalValidator:
    """
    –í–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è Task 31 - —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è EGNN –º–æ–¥–µ–ª–µ–π
    –Ω–∞ –∞–Ω—Ç–∏–±–∞–∫—Ç–µ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞—Ö.
    """
    
    def __init__(self):
        self.results_dir = Path("results/experimental_gap_validation")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º (–∏—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Ç–∏)
        self.model_paths = {
            "egnn_model3": Path("results/improved_egnn_ensemble/models/improved_egnn_model3/best_model.pth"),
            "egnn_model1": Path("results/improved_egnn_ensemble/models/improved_egnn_model1/best_model.pth"),
            "egnn_model2": Path("results/improved_egnn_ensemble/models/improved_egnn_model2/best_model.pth")
        }
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.experimental_data = self._load_experimental_data()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.predictions = {}
        self.ensemble_predictions = {}
        self.uncertainty_estimates = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.validation_metrics = {}
        self.domain_shift_analysis = {}
        
    def _load_experimental_data(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        data_file = Path("results/experimental_gap_validation/final_experimental_dataset.json")
        
        if not data_file.exists():
            # –ï—Å–ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –ø–æ–ª–Ω—ã–π
            data_file = Path("results/experimental_gap_validation/complete_experimental_dataset.json")
            
        if not data_file.exists():
            # –ï—Å–ª–∏ –∏ –ø–æ–ª–Ω–æ–≥–æ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π
            data_file = Path("results/experimental_gap_validation/expanded_experimental_dataset.json")
            
        if not data_file.exists():
            # –ï—Å–ª–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π
            data_file = Path("results/experimental_gap_validation/updated_experimental_gap_dataset.json")
        
        if not data_file.exists():
            raise FileNotFoundError(f"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data['metadata']['total_molecules']} –º–æ–ª–µ–∫—É–ª –∏–∑ {data_file.name}")
        return data
    
    def _load_egnn_model(self, model_path: Path) -> EGNNModel:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç EGNN –º–æ–¥–µ–ª—å –∏–∑ checkpoint."""
        
        if not model_path.exists():
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π (5 —Å–ª–æ—ë–≤, hidden_dim=256, –∫–∞–∫ –≤ checkpoint)
        config = EGNNConfig(
            node_feature_dim=11,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∞—Ç–æ–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            edge_feature_dim=0,   # 0 –∫–∞–∫ –≤ checkpoint (–Ω–µ 4!)
            hidden_dim=256,       # 256 –∫–∞–∫ –≤ checkpoint (–Ω–µ 128!)
            num_layers=5,         # 5 —Å–ª–æ—ë–≤ –∫–∞–∫ –≤ checkpoint
            output_dim=1,         # HOMO-LUMO Gap
            dropout=0.1,
            attention=True,
            normalize=True,
            update_coords=False   # –ù–µ –æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        )
        
        model = EGNNModel(config)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "egnn_model." –∏–∑ –∫–ª—é—á–µ–π
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith('egnn_model.'):
                new_key = key[11:]  # –£–±–∏—Ä–∞–µ–º "egnn_model."
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value
        
        model.load_state_dict(new_state_dict)
        model.eval()
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path.name}")
        
        return model
    
    def _smiles_to_graph(self, smiles: str) -> Optional[Dict]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç SMILES –≤ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–π –≥—Ä–∞—Ñ –¥–ª—è EGNN."""
        
        if not RDKIT_AVAILABLE:
            logger.error("RDKit –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å SMILES.")
            return None
        
        try:
            # –°–æ–∑–¥–∞–µ–º –º–æ–ª–µ–∫—É–ª—É –∏–∑ SMILES
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –º–æ–ª–µ–∫—É–ª—É –∏–∑ SMILES: {smiles}")
                return None
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–¥–æ—Ä–æ–¥—ã
            mol = Chem.AddHs(mol)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            AllChem.EmbedMolecule(mol, randomSeed=42)
            AllChem.MMFFOptimizeMolecule(mol)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ç–æ–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            node_features = []
            coordinates = []
            
            for atom in mol.GetAtoms():
                # –ë–∞–∑–æ–≤—ã–µ –∞—Ç–æ–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (11 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
                features = [
                    atom.GetAtomicNum(),                    # –ê—Ç–æ–º–Ω—ã–π –Ω–æ–º–µ—Ä
                    atom.GetDegree(),                       # –°—Ç–µ–ø–µ–Ω—å
                    atom.GetFormalCharge(),                 # –§–æ—Ä–º–∞–ª—å–Ω—ã–π –∑–∞—Ä—è–¥
                    atom.GetHybridization().real,           # –ì–∏–±—Ä–∏–¥–∏–∑–∞—Ü–∏—è
                    int(atom.GetIsAromatic()),              # –ê—Ä–æ–º–∞—Ç–∏—á–Ω–æ—Å—Ç—å
                    atom.GetNumRadicalElectrons(),          # –†–∞–¥–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–∫—Ç—Ä–æ–Ω—ã
                    int(atom.IsInRing()),                   # –í –∫–æ–ª—å—Ü–µ
                    atom.GetMass(),                         # –ê—Ç–æ–º–Ω–∞—è –º–∞—Å—Å–∞
                    atom.GetTotalValence(),                 # –í–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å
                    atom.GetNumImplicitHs(),                # –ù–µ—è–≤–Ω—ã–µ –≤–æ–¥–æ—Ä–æ–¥—ã
                    int(atom.GetChiralTag() != Chem.ChiralType.CHI_UNSPECIFIED)  # –•–∏—Ä–∞–ª—å–Ω–æ—Å—Ç—å
                ]
                node_features.append(features)
                
                # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                pos = mol.GetConformer().GetAtomPosition(atom.GetIdx())
                coordinates.append([pos.x, pos.y, pos.z])
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–≤—è–∑–∏ (–±–µ–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–≤—è–∑–µ–π, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –±–µ–∑ –Ω–∏—Ö)
            edge_indices = []
            
            for bond in mol.GetBonds():
                i = bond.GetBeginAtomIdx()
                j = bond.GetEndAtomIdx()
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑—å –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã (–Ω–µ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ)
                edge_indices.extend([[i, j], [j, i]])
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Å–≤—è–∑–µ–π, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã
            if not edge_indices:
                edge_indices = [[], []]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤—ã
            node_features = np.array(node_features, dtype=np.float32)
            coordinates = np.array(coordinates, dtype=np.float32)
            edge_index = np.array(edge_indices, dtype=np.int64).T  # [2, E]
            edge_features = np.zeros((len(edge_indices), 0), dtype=np.float32)  # –ü—É—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–≤—è–∑–µ–π
            
            return {
                'node_features': node_features,
                'coordinates': coordinates,
                'edge_index': edge_index,
                'edge_features': edge_features,
                'n_atoms': len(node_features)
            }
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ SMILES {smiles}: {e}")
            return None
    
    def _prepare_molecular_data(self, molecules: List[Dict]) -> List[Dict]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π."""
        
        logger.info("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        prepared_molecules = []
        
        for mol_data in molecules:
            if not mol_data.get('smiles'):
                logger.warning(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º {mol_data['name']}: –Ω–µ—Ç SMILES")
                continue
            
            try:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º SMILES –≤ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–π –≥—Ä–∞—Ñ
                mol_graph = self._smiles_to_graph(mol_data['smiles'])
                
                if mol_graph is None:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ –¥–ª—è {mol_data['name']}")
                    continue
                
                # –î–æ–±–∞–≤–ª—è–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                mol_graph.update({
                    'name': mol_data['name'],
                    'experimental_gap': mol_data.get('gap_energy'),
                    'n_atoms': mol_data.get('n_atoms'),
                    'quality_score': mol_data.get('quality_score', 0.5),
                    'antibacterial_class': mol_data.get('antibacterial_class'),
                    'source': mol_data.get('source'),
                    'method': mol_data.get('method')
                })
                
                prepared_molecules.append(mol_graph)
                
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {mol_data['name']}: {e}")
                continue
        
        logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(prepared_molecules)} –º–æ–ª–µ–∫—É–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        return prepared_molecules
    
    def _predict_with_model(self, model: EGNNModel, molecules: List[Dict]) -> Dict[str, float]:
        """–î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –æ–¥–Ω–æ–π –º–æ–¥–µ–ª—å—é."""
        
        predictions = {}
        
        with torch.no_grad():
            for mol_data in molecules:
                try:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    node_features = torch.tensor(mol_data['node_features'], dtype=torch.float32)
                    coordinates = torch.tensor(mol_data['coordinates'], dtype=torch.float32)
                    edge_index = torch.tensor(mol_data['edge_index'], dtype=torch.long)
                    edge_features = torch.tensor(mol_data['edge_features'], dtype=torch.float32)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                    if edge_index.numel() == 0:
                        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–≤—è–∑–µ–π, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π edge_index
                        edge_index = torch.zeros((2, 0), dtype=torch.long)
                    
                    # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º edge_features, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –±–µ–∑ –Ω–∏—Ö
                    edge_features = None
                    
                    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    results = model(
                        x=node_features,
                        pos=coordinates,
                        edge_index=edge_index,
                        edge_attr=edge_features,
                        batch=None  # –û–¥–Ω–∞ –º–æ–ª–µ–∫—É–ª–∞
                    )
                    
                    prediction = results['prediction'].item()
                    predictions[mol_data['name']] = prediction
                    
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {mol_data['name']}: {e}")
                    continue
        
        return predictions
    
    def run_subtask_31_2(self):
        """
        Subtask 31.2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Gap —ç–Ω–µ—Ä–≥–∏–π –ª—É—á—à–µ–π EGNN Model 3
        """
        
        logger.info("üöÄ SUBTASK 31.2: –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø GAP –≠–ù–ï–†–ì–ò–ô –õ–£–ß–®–ï–ô EGNN MODEL 3")
        logger.info("="*80)
        
        try:
            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            logger.info("\nüìã –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–ª–µ–∫—É–ª...")
            
            molecules = self.experimental_data['molecules']
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–ª–µ–∫—É–ª—ã —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ Gap –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            valid_molecules = [mol for mol in molecules if mol.get('gap_energy') is not None]
            
            logger.info(f"üìä –ú–æ–ª–µ–∫—É–ª —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ Gap: {len(valid_molecules)}")
            
            prepared_molecules = self._prepare_molecular_data(valid_molecules)
            
            if not prepared_molecules:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –º–æ–ª–µ–∫—É–ª—ã –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
            
            # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (Model 3)
            logger.info("\nü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π EGNN Model 3...")
            
            best_model = self._load_egnn_model(self.model_paths["egnn_model3"])
            
            # 3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é
            logger.info("\nüîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é...")
            
            best_predictions = self._predict_with_model(best_model, prepared_molecules)
            self.predictions['egnn_model3'] = best_predictions
            
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(best_predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
            
            # 4. Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è uncertainty estimation
            logger.info("\nüéØ Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è uncertainty estimation...")
            
            ensemble_predictions = {}
            all_model_predictions = []
            
            for model_name, model_path in self.model_paths.items():
                if model_path.exists():
                    try:
                        model = self._load_egnn_model(model_path)
                        predictions = self._predict_with_model(model, prepared_molecules)
                        self.predictions[model_name] = predictions
                        all_model_predictions.append(predictions)
                        logger.info(f"‚úÖ {model_name}: {len(predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {model_name}: {e}")
            
            # –í—ã—á–∏—Å–ª—è–µ–º ensemble —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if len(all_model_predictions) >= 2:
                for mol_name in best_predictions.keys():
                    mol_predictions = [pred.get(mol_name) for pred in all_model_predictions if pred.get(mol_name) is not None]
                    
                    if len(mol_predictions) >= 2:
                        ensemble_predictions[mol_name] = {
                            'mean': np.mean(mol_predictions),
                            'std': np.std(mol_predictions),
                            'min': np.min(mol_predictions),
                            'max': np.max(mol_predictions),
                            'n_models': len(mol_predictions)
                        }
                
                self.ensemble_predictions = ensemble_predictions
                logger.info(f"‚úÖ Ensemble —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è {len(ensemble_predictions)} –º–æ–ª–µ–∫—É–ª")
            
            # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            logger.info("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
            
            predictions_file = self.results_dir / "task_31_predictions.json"
            
            results = {
                'metadata': {
                    'timestamp': time.time(),
                    'best_model': 'egnn_model3',
                    'expected_qm9_performance': {
                        'mae': 0.076,
                        'r2': 0.9931
                    },
                    'n_molecules': len(prepared_molecules),
                    'n_ensemble_models': len(all_model_predictions)
                },
                'predictions': self.predictions,
                'ensemble_predictions': self.ensemble_predictions,
                'experimental_data': {mol['name']: {
                    'gap_energy': mol['gap_energy'],
                    'n_atoms': mol['n_atoms'],
                    'quality_score': mol['quality_score'],
                    'antibacterial_class': mol['antibacterial_class']
                } for mol in valid_molecules}
            }
            
            with open(predictions_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {predictions_file}")
            
            # 6. –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
            logger.info("\n‚úÖ SUBTASK 31.2 –ó–ê–í–ï–†–®–ï–ù")
            logger.info("="*60)
            logger.info(f"üéØ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: EGNN Model 3")
            logger.info(f"üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ–ª—É—á–µ–Ω–æ: {len(best_predictions)}")
            logger.info(f"üé≤ Ensemble –º–æ–¥–µ–ª–µ–π: {len(all_model_predictions)}")
            logger.info(f"üìà Uncertainty estimation: {'‚úÖ' if ensemble_predictions else '‚ùå'}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Subtask 31.2: {e}")
            raise
    
    def run_subtask_31_3(self):
        """
        Subtask 31.3: –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        
        logger.info("üöÄ SUBTASK 31.3: –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –° –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò")
        logger.info("="*80)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predictions_file = self.results_dir / "task_31_predictions.json"
            
            if not predictions_file.exists():
                raise FileNotFoundError("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ Subtask 31.2")
            
            with open(predictions_file, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            best_predictions = results['predictions']['egnn_model3']
            experimental_data = results['experimental_data']
            
            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            logger.info("\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            
            analysis_data = []
            
            for mol_name, pred_gap in best_predictions.items():
                if mol_name in experimental_data:
                    exp_data = experimental_data[mol_name]
                    exp_gap = exp_data['gap_energy']
                    
                    if exp_gap is not None:
                        analysis_data.append({
                            'name': mol_name,
                            'predicted_gap': pred_gap,
                            'experimental_gap': exp_gap,
                            'n_atoms': exp_data['n_atoms'],
                            'quality_score': exp_data['quality_score'],
                            'antibacterial_class': exp_data['antibacterial_class'],
                            'absolute_error': abs(pred_gap - exp_gap),
                            'relative_error': abs(pred_gap - exp_gap) / exp_gap * 100
                        })
            
            if not analysis_data:
                raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            
            df = pd.DataFrame(analysis_data)
            logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(df)} –ø–∞—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            # 2. –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
            logger.info("\nüìà –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏...")
            
            predicted = df['predicted_gap'].values
            experimental = df['experimental_gap'].values
            
            # MAE, RMSE, R¬≤
            mae = np.mean(np.abs(predicted - experimental))
            rmse = np.sqrt(np.mean((predicted - experimental) ** 2))
            r2 = stats.pearsonr(predicted, experimental)[0] ** 2
            
            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            pearson_r, pearson_p = stats.pearsonr(predicted, experimental)
            spearman_r, spearman_p = stats.spearmanr(predicted, experimental)
            
            # Domain Shift Factor
            qm9_mae = 0.076  # –û–∂–∏–¥–∞–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ QM9
            domain_shift_factor = mae / qm9_mae
            
            overall_metrics = {
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'pearson_correlation': pearson_r,
                'pearson_p_value': pearson_p,
                'spearman_correlation': spearman_r,
                'spearman_p_value': spearman_p,
                'domain_shift_factor': domain_shift_factor,
                'n_samples': len(df)
            }
            
            logger.info(f"üìä MAE: {mae:.3f} eV")
            logger.info(f"üìä RMSE: {rmse:.3f} eV")
            logger.info(f"üìä R¬≤: {r2:.3f}")
            logger.info(f"üìä Pearson r: {pearson_r:.3f} (p={pearson_p:.3e})")
            logger.info(f"üìä Domain Shift Factor: {domain_shift_factor:.2f}x")
            
            # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤
            logger.info("\nüîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–ª–µ–∫—É–ª...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä—É–ø–ø—ã —Ä–∞–∑–º–µ—Ä–æ–≤
            def get_size_group(n_atoms):
                if n_atoms <= 30:
                    return 'small'
                elif n_atoms <= 60:
                    return 'medium'
                elif n_atoms <= 100:
                    return 'large'
                elif n_atoms <= 200:
                    return 'xlarge'
                else:
                    return 'xxlarge'
            
            df['size_group'] = df['n_atoms'].apply(get_size_group)
            
            size_group_metrics = {}
            
            for group in df['size_group'].unique():
                group_df = df[df['size_group'] == group]
                
                if len(group_df) >= 2:  # –ú–∏–Ω–∏–º—É–º 2 —Ç–æ—á–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    group_pred = group_df['predicted_gap'].values
                    group_exp = group_df['experimental_gap'].values
                    
                    group_mae = np.mean(np.abs(group_pred - group_exp))
                    group_rmse = np.sqrt(np.mean((group_pred - group_exp) ** 2))
                    
                    if len(group_df) >= 3:  # –ú–∏–Ω–∏–º—É–º 3 —Ç–æ—á–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                        group_r, group_p = stats.pearsonr(group_pred, group_exp)
                        group_r2 = group_r ** 2
                    else:
                        group_r, group_p, group_r2 = np.nan, np.nan, np.nan
                    
                    size_group_metrics[group] = {
                        'n_samples': len(group_df),
                        'mae': group_mae,
                        'rmse': group_rmse,
                        'r2': group_r2,
                        'pearson_r': group_r,
                        'pearson_p': group_p,
                        'domain_shift_factor': group_mae / qm9_mae,
                        'size_range': f"{group_df['n_atoms'].min()}-{group_df['n_atoms'].max()}"
                    }
                    
                    logger.info(f"  {group.upper()}: n={len(group_df)}, MAE={group_mae:.3f} eV, R¬≤={group_r2:.3f}")
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
            logger.info("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            
            validation_results = {
                'metadata': {
                    'timestamp': time.time(),
                    'analysis_type': 'experimental_validation',
                    'qm9_baseline_mae': qm9_mae
                },
                'overall_metrics': overall_metrics,
                'size_group_metrics': size_group_metrics,
                'detailed_results': df.to_dict('records')
            }
            
            validation_file = self.results_dir / "task_31_validation_metrics.json"
            
            with open(validation_file, 'w', encoding='utf-8') as f:
                json.dump(validation_results, f, indent=2, ensure_ascii=False)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ CSV –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            csv_file = self.results_dir / "task_31_validation_results.csv"
            df.to_csv(csv_file, index=False)
            
            logger.info(f"üíæ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {validation_file}")
            logger.info(f"üíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {csv_file}")
            
            # 5. –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
            logger.info("\n‚úÖ SUBTASK 31.3 –ó–ê–í–ï–†–®–ï–ù")
            logger.info("="*60)
            logger.info(f"üìä –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: MAE={mae:.3f} eV, R¬≤={r2:.3f}")
            logger.info(f"üîÑ Domain Shift: {domain_shift_factor:.2f}x –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ—Ç QM9")
            logger.info(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å: p={pearson_p:.2e}")
            logger.info(f"üéØ –ì—Ä—É–ø–ø —Ä–∞–∑–º–µ—Ä–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(size_group_metrics)}")
            
            self.validation_metrics = validation_results
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Subtask 31.3: {e}")
            raise
    
    def run_full_task_31(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é Task 31."""
        
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ô TASK 31: –í–ê–õ–ò–î–ê–¶–ò–Ø –ù–ê –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•")
        logger.info("="*80)
        
        try:
            # Subtask 31.1 —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö)
            logger.info("‚úÖ Subtask 31.1: –ü–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - –ó–ê–í–ï–†–®–ï–ù")
            
            # Subtask 31.2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            self.run_subtask_31_2()
            
            # Subtask 31.3: –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            self.run_subtask_31_3()
            
            # TODO: Subtask 31.4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—Ç—á–µ—Ç
            # TODO: Subtask 31.5: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            
            logger.info("\nüéâ TASK 31 –ß–ê–°–¢–ò–ß–ù–û –ó–ê–í–ï–†–®–ï–ù–ê")
            logger.info("‚úÖ Subtasks 31.1-31.3 –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")
            logger.info("üîÑ Subtasks 31.4-31.5 —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Task 31: {e}")
            raise


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    
    try:
        validator = Task31ExperimentalValidator()
        validator.run_full_task_31()
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ main: {e}")
        raise


if __name__ == "__main__":
    main()